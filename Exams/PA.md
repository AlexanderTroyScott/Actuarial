:memo: Note: I had initially summarized the PA study material as a away to organize review material for a coworker and myself. I was surprised to learn that others were finding the material useful and it had continued to generate hits even years after I had passed the exam. Unfortunately I have not had the time to go back and make additions; therefore, I decided to copy everything over to this github repository so that it could be better maintained by the community and put a link to directing you here.


# 6. Generalized Linear Models

##### a) Implement ordinary least squares regression in R and understand model assumptions.
[![Alt text](https://img.youtube.com/vi/PaFPbb66DxQ/0.jpg)](https://www.youtube.com/watch?v=PaFPbb66DxQ)

[![Alt text](https://img.youtube.com/vi/nk2CQITm_eo/0.jpg)](https://www.youtube.com/watch?v=nk2CQITm_eo)

[![Alt text](https://img.youtube.com/vi/u1cc1r_Y7M0/0.jpg)](https://www.youtube.com/watch?v=u1cc1r_Y7M0)

##### b) Understand the specifications of the GLM and the model assumptions. 
1. Linear Regression (Ordinary Least Squares Regression)
2. Logistic Regression
3. Regularized Regression 
    * Ridge
    * Lasso
    * Elastic Net

###### Logistic Regression

[![Alt text](https://img.youtube.com/vi/yIYKR4sgzI8/0.jpg)](https://www.youtube.com/watch?v=yIYKR4sgzI8)

[![Alt text](https://img.youtube.com/vi/vN5cNN2-HWE/0.jpg)](https://www.youtube.com/watch?v=vN5cNN2-HWE)

[![Alt text](https://img.youtube.com/vi/BfKanl1aSG0/0.jpg)](https://www.youtube.com/watch?v=BfKanl1aSG0)

[![Alt text](https://img.youtube.com/vi/xxFYro8QuXA/0.jpg)](https://www.youtube.com/watch?v=xxFYro8QuXA)

[![Alt text](https://img.youtube.com/vi/9T0wlKdew6I/0.jpg)](https://www.youtube.com/watch?v=9T0wlKdew6I)

[![Alt text](https://img.youtube.com/vi/JC56jS2gVUE/0.jpg)](https://www.youtube.com/watch?v=JC56jS2gVUE)

[![Alt text](https://img.youtube.com/vi/C4N3_XJJ-jU/0.jpg)](https://www.youtube.com/watch?v=C4N3_XJJ-jU)

###### Regularized Regression

[![Alt text](https://img.youtube.com/vi/Q81RR3yKn30/0.jpg)](https://www.youtube.com/watch?v=Q81RR3yKn30)

[![Alt text](https://img.youtube.com/vi/NGf0voTMlcs/0.jpg)](https://www.youtube.com/watch?v=NGf0voTMlcs)

[![Alt text](https://img.youtube.com/vi/1dKRdX9bfIo/0.jpg)](https://www.youtube.com/watch?v=1dKRdX9bfIo)

[![Alt text](https://img.youtube.com/vi/ctmNq7FgbvI/0.jpg)](https://www.youtube.com/watch?v=ctmNq7FgbvI)

###### Regularized Regression

##### c) Create new features appropriate for GLMs. 



##### d) Interpret model coefficients, interaction terms, offsets, and weights. 

See casact article

##### e) Select and validate a GLM appropriately. 

[![Alt text](https://img.youtube.com/vi/fSytzGwwBVw/0.jpg)](https://www.youtube.com/watch?v=fSytzGwwBVw)

[![Alt text](https://img.youtube.com/vi/Kdsp6soqA7o/0.jpg)](https://www.youtube.com/watch?v=Kdsp6soqA7o)

[![Alt text](https://img.youtube.com/vi/vP06aMoz4v8/0.jpg)](https://www.youtube.com/watch?v=vP06aMoz4v8)

[![Alt text](https://img.youtube.com/vi/4jRBRDbJemM/0.jpg)](https://www.youtube.com/watch?v=4jRBRDbJemM)

[![Alt text](https://img.youtube.com/vi/qcvAqAH60Yw/0.jpg)](https://www.youtube.com/watch?v=qcvAqAH60Yw)

##### f) Explain the concepts of bias, variance, model complexity, and the bias-variance trade-off. 

The more fit the model is to the training data, the less bias there will be; however, this tends to result in more variance in the testing data.

**Overfitting** - "Overfitting" to the training data resulting in **low bias, but high variance**

**Underfitting** - "Underfitting" to the training data resulting in **high bias, but low variance**

[![Alt text](https://img.youtube.com/vi/EuBBz3bI-aA/0.jpg)](https://www.youtube.com/watch?v=EuBBz3bI-aA)

##### g) Select appropriate hyperparameters for regularized regression 

# 7. Decision Trees 

## a) Understand the basic motivation behind decision trees. 

[![Alt text](https://img.youtube.com/vi/7VeUPuFGJHk/0.jpg)](https://www.youtube.com/watch?v=7VeUPuFGJHk)

[![Alt text](https://img.youtube.com/vi/wpNl-JwwplA/0.jpg)](https://www.youtube.com/watch?v=wpNl-JwwplA)

## b) Construct regression and classification trees. 

[![Alt text](https://img.youtube.com/vi/g9c66TUylZ4/0.jpg)](https://www.youtube.com/watch?v=g9c66TUylZ4)

[![Alt text](https://img.youtube.com/vi/D0efHEJsfHo/0.jpg)](https://www.youtube.com/watch?v=D0efHEJsfHo)

## c) Use bagging and random forests to improve accuracy. 

[![Alt text](https://img.youtube.com/vi/J4Wdy0Wc_xQ/0.jpg)](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ)

[![Alt text](https://img.youtube.com/vi/nyxTdL_4Q-Q/0.jpg)](https://www.youtube.com/watch?v=nyxTdL_4Q-Q)

[![Alt text](https://img.youtube.com/vi/6EXPYzbfLCE/0.jpg)](https://www.youtube.com/watch?v=6EXPYzbfLCE)

## d) Use boosting to improve accuracy. 

[![Alt text](https://img.youtube.com/vi/LsK-xG1cLYA/0.jpg)](https://www.youtube.com/watch?v=LsK-xG1cLYA)

[![Alt text](https://img.youtube.com/vi/3CC4N4z3GJc/0.jpg)](https://www.youtube.com/watch?v=3CC4N4z3GJc)

[![Alt text](https://img.youtube.com/vi/2xudPOBz-vs/0.jpg)](https://www.youtube.com/watch?v=2xudPOBz-vs)

[![Alt text](https://img.youtube.com/vi/jxuNLH5dXCs/0.jpg)](https://www.youtube.com/watch?v=jxuNLH5dXCs)

[![Alt text](https://img.youtube.com/vi/StWY5QWMXCw/0.jpg)](https://www.youtube.com/watch?v=StWY5QWMXCw)

## e) Select appropriate hyperparameters for decision trees and related techniques. 

**Random Forest Hyperparameters**
1. Impurity measure - In most cases there is not much difference between selecting one method over the other. 
    * Gini - Default
    * Entropy - More computationally intensive since it uses the logarithmic function
2. Splitter - How a split is determined at each node. 
    * Best - Default - chooses the one based on the impurity measures and is computationally intensive
    * Random - Chooses a random feature and generally ends up with longer and less precise trees, but can reduce overfitting
3. Max_Depth - Controlling this is the main way to combat overfitting
    * None - Default
4. ntree - Number of trees in the forest
5. mtry - Number of variables compared in the trees

**GBM Hyperparameters**
